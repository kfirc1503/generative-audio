# Training parameters
n_epochs: 16  # Set to null if using n_steps
#n_steps: null  # Set to null if using n_epochs
checkpoint_dir: "../../../../../../data/checkpoints/restoration_model"

# Main training configuration
inpainting_training_configuration:
  # Wandb configuration
  use_wandb: true
  wandb_project_name: "generative-audio"
  wandb_run_name: "restoration-inpainting-model-128ms-gap-size"  # Will be auto-generated if not specified
  wandb_artifact_name: "restoration_model"
  wandb_tags:
    - "128ms_gap"            # Gap length
    - "use_vad"              # voice activity is used
    - "2.044sec_audio_len"
    - "libriSpeech_dataset"
    - "dropout_0.2"
  # Model configuration
  device: "cuda"


  model_configuration:
    in_channels: 1
    out_channels: 1
    dropout: 0.2
    # Add other UNet specific configurations here

  # Data configuration
  data_configuration:
    clean_path: "../../../../../../data/LibriSpeech/LibriSpeech/train-clean-360"
    sample_rate: 16000
    missing_length_seconds: 0.128
    missing_start_seconds: 0.4
#    sub_sample_length_seconds: 1.022
    sub_sample_length_seconds: 2.044

    target_dB_FS: -25.0
    target_dB_FS_floating_value: 0
    use_vad: true
    stft_configuration:
      nfft: 255
      win_length: 255
      hop_length: 128

  # Dataloader configuration
  dataloader_configuration:
    batch_size: 128
    shuffle: true
    num_workers: 8
    pin_memory: true

  # Optimizer configuration
  optimizer_configuration:
    type: "Adam"
    args:
      lr: 1.0e-4
      betas: [0.5, 0.999]

## Validation configuration (optional)
#validation_data_configuration:
#  clean_path: "../../../../../../data/clean/test"
#  sample_rate: 16000
#  missing_length_seconds: 0.256
#  missing_start_seconds: 0.4
#  sub_sample_length_seconds: 1.533
##  sub_sample_length_seconds: 2.044
#
#  target_dB_FS: -25.0
#  target_dB_FS_floating_value: 0
#  use_vad: true
#  stft_configuration:
#    nfft: 255
#    win_length: 255
#    hop_length: 128